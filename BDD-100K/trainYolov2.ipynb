{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(images, boxes=None):\n",
    "    \"\"\"\n",
    "    Process the data\n",
    "    \"\"\"\n",
    "    images = [PIL.Image.fromarray(i) for i in images]\n",
    "    orig_size = np.array([images[0].width, images[0].height])\n",
    "    orig_size = np.expand_dims(orig_size, axis=0)\n",
    "    \n",
    "    # Image preprocessing\n",
    "    processed_images = [i.resize((416, 416), PIL.Image.BICUBIC) for i in images]\n",
    "    processed_images = [np.array(image, dtype=np.float) for image in processed_images]\n",
    "    processed_images = [image/255. for image in processed_images]\n",
    "    \n",
    "    if boxes is not None:\n",
    "        # Box preprocessing\n",
    "        # Original boxes stored as 1D list of class, x_min, y_min, x_max, y_max\n",
    "        boxes = [box.reshape((-1, 5)) for box in boxes]\n",
    "        \n",
    "        # Get extents as y_min, x_min, y_max, x_max, class for comparison with model output\n",
    "        box_extents = [box[:, [2,1,4,3,0]] for box in boxes]\n",
    "        \n",
    "        # Get box parameters as x_center, y_center, box_width, box_height, class\n",
    "        boxes_xy = [0.5 * (box[:, 3:5] + box[:, 1:3]) for box in boxes]\n",
    "        boxes_wh = [box[:, 3:5] - box[:, 1:3] for box in boxes]\n",
    "        boxes_xy = [box_xy / orig_size for box_xy in boxes_xy]\n",
    "        boxes_wh = [box_wh / orig_size for box_wh in boxes_wh]\n",
    "        boxes = [np.concatenate((boxes_xy[i], boxes_wh[i], box[:, 0:1]), axis=-1) for i, box in enumerate(boxes)]\n",
    "        \n",
    "        # find the max number of boxes\n",
    "        max_boxes = 0\n",
    "        for boxz in boxes:\n",
    "            if boxz.shape[0] > max_boxes:\n",
    "                max_boxes = boxz.shape[0]\n",
    "                \n",
    "        # add zero pad for training\n",
    "        for i, boxz in enumerate(boxes):\n",
    "            if boxz.shape[0] <  max_boxes:\n",
    "                zero_padding = np.zeros((max_boxes - boxz.shape[0], 5), dtype=np.float32)\n",
    "                boxes[i] = np.vstack((boxz, zero_padding))\n",
    "        return np.array(processed_images), np.array(boxes)\n",
    "    else:\n",
    "        return np.array(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box1, box2):\n",
    "    \"\"\"\n",
    "    Returns the Intersection over Union (IoU) between box1 and box2\n",
    "    \n",
    "    Arguments: \n",
    "    box1: coordinates: (x1, y1, x2, y2)\n",
    "    box2: coordinates: (x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the intersection area of the two boxes. \n",
    "    xi1 = max(box1[0], box2[0])\n",
    "    yi1 = max(box1[1], box2[1])\n",
    "    xi2 = min(box1[2], box2[2])\n",
    "    yi2 = min(box1[3], box2[3])\n",
    "    \n",
    "    area_of_intersection = (xi2 - xi1) * (yi2 - yi1)\n",
    "    \n",
    "    # Calculate the union area of the two boxes\n",
    "    # A U B = A + B - A âˆ© B\n",
    "    A = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    B = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    union_area = A + B - area_of_intersection\n",
    "    \n",
    "    intersection_over_union = area_of_intersection/ union_area\n",
    "    \n",
    "    return intersection_over_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(anchors, class_names, load_pretrained=True, freeze_body = True):\n",
    "    \"\"\"\n",
    "    \n",
    "    load_pretrained: whether or not to load the pretrained model or initialize all weights\n",
    " \n",
    "    freeze_body: whether or not to freeze all weights except for the last layer\n",
    "    \n",
    "    Returns:\n",
    "    model_body : YOLOv2 with new output layer\n",
    "    model : YOLOv2 with custom loss Lambda layer  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    detector_mask_shape = (13, 13, 5, 1)\n",
    "    matching_boxes_shape = (13, 13, 5, 5)\n",
    "    \n",
    "    # Create model body\n",
    "    image_input = Input(shape=(416, 416, 3))\n",
    "    boxes_input = Input(shape=(None, 5))\n",
    "    detector_mask_input = Input(shape=detector_mask_shape)\n",
    "    matching_boxes_input = Input(shape=matching_boxes_shape)\n",
    "    \n",
    "    # Create model body\n",
    "    yolo_model = yolo_body(image_input, len(anchors), len(class_names))\n",
    "    topless_yolo = Model(yolo_model.input, yolo_model.layers[-2].output)\n",
    "    \n",
    "    if load_pretrained == True:\n",
    "        # Save topless yolo\n",
    "        topless_yolo_path = os.path.join('model_data', 'yolo_topless.h5')\n",
    "        if not os.path.exists(topless_yolo_path):\n",
    "            print('Creating Topless weights file')\n",
    "            yolo_path = os.path.join('model_data', 'yolo.h5')\n",
    "            model_body = load_model(yolo_path)\n",
    "            model_body = Model(model_body.inputs, model_body.layers[-2].output)\n",
    "            model_body.save_weights(topless_yolo_path)\n",
    "        topless_yolo.load_weights(topless_yolo_path)\n",
    "        \n",
    "    if freeze_body:\n",
    "        for layer in topless_yolo.layers:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    final_layer = Conv2D(len(anchors)*(5 + len(class_names)), (1, 1), activation='linear')(topless_yolo.output)\n",
    "    model_body = Model(image_input, final_layer)\n",
    "    \n",
    "    # Place model loss on CPU to reduce GPU memory usage.    \n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss', arguments={\n",
    "            'anchors': anchors, \n",
    "            'num_classes': len(class_names)})([model_body.output, boxes_input, detector_mask_input, matching_boxes_input])\n",
    "    \n",
    "    model = Model([model_body.input, boxes_input, detector_mask_input, matching_boxes_input], model_loss)\n",
    "    return model_body, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Filters YOLO boxes by thresholding on object and class confidence\n",
    "    Arguments: \n",
    "    box_confidence: Probability of the box containing the object\n",
    "    boxes: The box parameters : (x, y, h, w) \n",
    "           x, y -> Center of the box \n",
    "           h, w -> Height and width of the box w.r.t the image size\n",
    "    box_class_probs: Probability of all the classes for each box\n",
    "    threshold: Threshold value for box confidence\n",
    "    \n",
    "    Returns: \n",
    "    scores: containing the class probability score for the selected boxes\n",
    "    boxes: contains box coordinates for the selected boxes\n",
    "    classes: contains the index of the class detected by the selected boxes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the box scores: \n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    \n",
    "    # Find the box classes index with the maximum box score\n",
    "    box_classes = K.argmax(box_scores)\n",
    "    # Find the box classes with maximum box score\n",
    "    box_class_scores = K.max(box_scores, axis=-1)\n",
    "    \n",
    "    # Creating a mask for selecting the boxes that have box score greater than threshold\n",
    "    thresh_mask = box_class_scores >= threshold\n",
    "    # Selecting the scores, boxes and classes with box score greater than \n",
    "    # threshold by filtering the box score with the help of thresh_mask.\n",
    "    scores = tf.boolean_mask(tensor=box_class_scores, mask=thresh_mask)\n",
    "    classes = tf.boolean_mask(tensor=box_classes, mask=thresh_mask)\n",
    "    boxes = tf.boolean_mask(tensor=boxes, mask=thresh_mask)\n",
    "    \n",
    "    return scores, classes, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(scores, classes, boxes, max_boxes=10, iou_threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Non-maximal suppression is used to fix the multiple detections of the same object.\n",
    "    - Find the box_confidence (Probability of the box containing the object) for each detection.\n",
    "    - Find the bounding box with the highest box_confidence\n",
    "    - Suppress all the bounding boxes which have an IoU greater than 0.5 with the bounding box with the maximum box confidence.\n",
    "    \n",
    "    scores    -> containing the class probability score for the selected boxes.\n",
    "    boxes     -> contains box coordinates for the boxes selected after threshold masking.\n",
    "    classes   -> contains the index of the classes detected by the selected boxes.\n",
    "    max_boxes -> maximum number of predicted boxes to be returned after NMS filtering.\n",
    "    \n",
    "    Returns: \n",
    "    scores  -> predicted score for each box.\n",
    "    classes -> predicted class for each box.\n",
    "    boxes   -> predicted box coordinates.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Converting max_boxes to tensor \n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n",
    "    # Initialize the max_boxes_tensor\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))\n",
    "    \n",
    "    # Implement non-max suppression using tf.image.non_max_suppression()\n",
    "    # tf.image.non_max_suppression() ->  Returns the indices corresponding to the boxes you want to keep\n",
    "    \n",
    "    indices = tf.image.non_max_suppression(boxes=boxes, scores=scores, max_output_size=max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "    \n",
    "    # K.gather() is used to select only indices present in 'indices' variable from scores, boxes and classe\n",
    "    \n",
    "    scores = tf.gather(scores, indices)\n",
    "    classes = tf.gather(classes, indices)\n",
    "    boxes = tf.gather(boxes, indices)\n",
    "    \n",
    "    return scores, classes , boxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ed2cbf1b326c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the path of the test image data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reading and storing the test image data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading the path of the test image data\n",
    "test = glob('data/test/*.jpg')\n",
    "# Reading and storing the test image data\n",
    "test_data = []\n",
    "for i in test:\n",
    "    test_data.append(plt.imread(i))\n",
    "# Processing the test image data \n",
    "test_data = process_data(test_data)\n",
    " \n",
    "# Predicting the scores, boxes, classes for the given input image\n",
    "scores, boxes, classes, model_body, input_image_shape = load_yolo(model_body, class_names, anchors)\n",
    "# Drawing the bounding boxes\n",
    "draw(model_body, scores, boxes, classes,input_image_shape, test_data, image_set='all', out_path='data/test/output/',save_all=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
