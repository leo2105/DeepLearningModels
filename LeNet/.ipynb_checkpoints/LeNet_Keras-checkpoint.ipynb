{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras.layers import Lambda, BatchNormalization, Dropout\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand = np.random.choice(60000)\n",
    "plt.imshow(X_train[rand], 'gray')\n",
    "plt.title(y_train[rand])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - 127.5) / 127.5\n",
    "X_test = (X_test - 127.5) / 127.5\n",
    "X_train = X_train[...,None]\n",
    "X_test = X_test[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 16)        144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,426\n",
      "Trainable params: 10,362\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: K.dropout(x, level=0.1), input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D())\n",
    "model.add(Lambda(lambda x: K.dropout(x, level=0.1)))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Lambda(lambda x: K.dropout(x, level=0.5)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(1e-2),\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 1.0428 - acc: 0.6913 - val_loss: 0.4772 - val_acc: 0.8469\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.3986 - acc: 0.8723 - val_loss: 0.3235 - val_acc: 0.8962\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3045 - acc: 0.9026 - val_loss: 0.2527 - val_acc: 0.9221\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2567 - acc: 0.9192 - val_loss: 0.2166 - val_acc: 0.9306\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2274 - acc: 0.9269 - val_loss: 0.2007 - val_acc: 0.9374\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2093 - acc: 0.9340 - val_loss: 0.1895 - val_acc: 0.9412\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1964 - acc: 0.9380 - val_loss: 0.1810 - val_acc: 0.9429\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1862 - acc: 0.9417 - val_loss: 0.1675 - val_acc: 0.9488\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1766 - acc: 0.9455 - val_loss: 0.1570 - val_acc: 0.9489\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1695 - acc: 0.9469 - val_loss: 0.1508 - val_acc: 0.9535\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1622 - acc: 0.9492 - val_loss: 0.1425 - val_acc: 0.9545\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1564 - acc: 0.9505 - val_loss: 0.1452 - val_acc: 0.9547\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1521 - acc: 0.9524 - val_loss: 0.1422 - val_acc: 0.9554\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1485 - acc: 0.9545 - val_loss: 0.1305 - val_acc: 0.9602\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1462 - acc: 0.9543 - val_loss: 0.1298 - val_acc: 0.9606\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1431 - acc: 0.9565 - val_loss: 0.1303 - val_acc: 0.9601\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1410 - acc: 0.9556 - val_loss: 0.1277 - val_acc: 0.9610\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1383 - acc: 0.9569 - val_loss: 0.1263 - val_acc: 0.9602\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1350 - acc: 0.9580 - val_loss: 0.1182 - val_acc: 0.9645\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1316 - acc: 0.9584 - val_loss: 0.1245 - val_acc: 0.9598\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1291 - acc: 0.9587 - val_loss: 0.1134 - val_acc: 0.9639\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1274 - acc: 0.9602 - val_loss: 0.1144 - val_acc: 0.9654\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1277 - acc: 0.9605 - val_loss: 0.1114 - val_acc: 0.9636\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1256 - acc: 0.9610 - val_loss: 0.1191 - val_acc: 0.9617\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1221 - acc: 0.9629 - val_loss: 0.1134 - val_acc: 0.9651\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1258 - acc: 0.9614 - val_loss: 0.1097 - val_acc: 0.9636\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1200 - acc: 0.9622 - val_loss: 0.1111 - val_acc: 0.9652\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1200 - acc: 0.9619 - val_loss: 0.1089 - val_acc: 0.9655\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1195 - acc: 0.9630 - val_loss: 0.1110 - val_acc: 0.9638\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1166 - acc: 0.9634 - val_loss: 0.1079 - val_acc: 0.9656\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1179 - acc: 0.9639 - val_loss: 0.1081 - val_acc: 0.9654\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1171 - acc: 0.9637 - val_loss: 0.1074 - val_acc: 0.9680\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1124 - acc: 0.9655 - val_loss: 0.1012 - val_acc: 0.9680\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1154 - acc: 0.9636 - val_loss: 0.1094 - val_acc: 0.9667\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1099 - acc: 0.9655 - val_loss: 0.1054 - val_acc: 0.9681\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1117 - acc: 0.9663 - val_loss: 0.1002 - val_acc: 0.9683\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1105 - acc: 0.9647 - val_loss: 0.1008 - val_acc: 0.9690\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1079 - acc: 0.9673 - val_loss: 0.0979 - val_acc: 0.9702\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1091 - acc: 0.9659 - val_loss: 0.1052 - val_acc: 0.9665\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1080 - acc: 0.9659 - val_loss: 0.1020 - val_acc: 0.9666\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1072 - acc: 0.9660 - val_loss: 0.0956 - val_acc: 0.9692\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1095 - acc: 0.9665 - val_loss: 0.0991 - val_acc: 0.9685\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1088 - acc: 0.9661 - val_loss: 0.1013 - val_acc: 0.9673\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1089 - acc: 0.9663 - val_loss: 0.0931 - val_acc: 0.9729\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1068 - acc: 0.9663 - val_loss: 0.0968 - val_acc: 0.9704\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1047 - acc: 0.9675 - val_loss: 0.0922 - val_acc: 0.9702\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1053 - acc: 0.9677 - val_loss: 0.1006 - val_acc: 0.9693\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1053 - acc: 0.9675 - val_loss: 0.0995 - val_acc: 0.9697\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1069 - acc: 0.9670 - val_loss: 0.0959 - val_acc: 0.9687\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1031 - acc: 0.9668 - val_loss: 0.0995 - val_acc: 0.9689\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1002 - acc: 0.9688 - val_loss: 0.0936 - val_acc: 0.9699\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1004 - acc: 0.9679 - val_loss: 0.0915 - val_acc: 0.9724\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1004 - acc: 0.9684 - val_loss: 0.1004 - val_acc: 0.9693\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1003 - acc: 0.9684 - val_loss: 0.0943 - val_acc: 0.9706\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1002 - acc: 0.9680 - val_loss: 0.0928 - val_acc: 0.9684\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1005 - acc: 0.9683 - val_loss: 0.0937 - val_acc: 0.9687\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0994 - acc: 0.9688 - val_loss: 0.0947 - val_acc: 0.9703\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1000 - acc: 0.9689 - val_loss: 0.0920 - val_acc: 0.9728\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0993 - acc: 0.9690 - val_loss: 0.0939 - val_acc: 0.9718\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0981 - acc: 0.9690 - val_loss: 0.0938 - val_acc: 0.9700\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0985 - acc: 0.9693 - val_loss: 0.0929 - val_acc: 0.9698\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0988 - acc: 0.9693 - val_loss: 0.0922 - val_acc: 0.9719\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0970 - acc: 0.9698 - val_loss: 0.0940 - val_acc: 0.9687\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0983 - acc: 0.9693 - val_loss: 0.0914 - val_acc: 0.9740\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0958 - acc: 0.9696 - val_loss: 0.0887 - val_acc: 0.9735\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0970 - acc: 0.9692 - val_loss: 0.0881 - val_acc: 0.9729\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0935 - acc: 0.9704 - val_loss: 0.0932 - val_acc: 0.9714\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0956 - acc: 0.9697 - val_loss: 0.0886 - val_acc: 0.9721\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0945 - acc: 0.9703 - val_loss: 0.0898 - val_acc: 0.9713\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0941 - acc: 0.9709 - val_loss: 0.0929 - val_acc: 0.9706\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0936 - acc: 0.9708 - val_loss: 0.0920 - val_acc: 0.9721\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0925 - acc: 0.9709 - val_loss: 0.0864 - val_acc: 0.9731\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0940 - acc: 0.9699 - val_loss: 0.0848 - val_acc: 0.9723\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0927 - acc: 0.9707 - val_loss: 0.0919 - val_acc: 0.9708\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0906 - acc: 0.9721 - val_loss: 0.0923 - val_acc: 0.9704\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0941 - acc: 0.9703 - val_loss: 0.0847 - val_acc: 0.9750\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0926 - acc: 0.9708 - val_loss: 0.0874 - val_acc: 0.9708\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0950 - acc: 0.9703 - val_loss: 0.0902 - val_acc: 0.9710\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0899 - acc: 0.9711 - val_loss: 0.0843 - val_acc: 0.9749\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0927 - acc: 0.9707 - val_loss: 0.0840 - val_acc: 0.9732\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0916 - acc: 0.9717 - val_loss: 0.0871 - val_acc: 0.9706\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0920 - acc: 0.9708 - val_loss: 0.0878 - val_acc: 0.9723\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0902 - acc: 0.9711 - val_loss: 0.0855 - val_acc: 0.9742\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0909 - acc: 0.9708 - val_loss: 0.0924 - val_acc: 0.9713\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0905 - acc: 0.9713 - val_loss: 0.0908 - val_acc: 0.9709\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0896 - acc: 0.9713 - val_loss: 0.0900 - val_acc: 0.9713\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0915 - acc: 0.9714 - val_loss: 0.0877 - val_acc: 0.9741\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0906 - acc: 0.9706 - val_loss: 0.0840 - val_acc: 0.9734\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0866 - acc: 0.9728 - val_loss: 0.0863 - val_acc: 0.9739\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0901 - acc: 0.9718 - val_loss: 0.0851 - val_acc: 0.9727\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0912 - acc: 0.9715 - val_loss: 0.0904 - val_acc: 0.9709\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0896 - acc: 0.9719 - val_loss: 0.0853 - val_acc: 0.9726\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0881 - acc: 0.9722 - val_loss: 0.0880 - val_acc: 0.9714\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0883 - acc: 0.9719 - val_loss: 0.0811 - val_acc: 0.9743\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0865 - acc: 0.9724 - val_loss: 0.0859 - val_acc: 0.9732\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0884 - acc: 0.9726 - val_loss: 0.0815 - val_acc: 0.9752\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0889 - acc: 0.9720 - val_loss: 0.0821 - val_acc: 0.9749\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0872 - acc: 0.9721 - val_loss: 0.0821 - val_acc: 0.9741\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0867 - acc: 0.9728 - val_loss: 0.0796 - val_acc: 0.9731\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0884 - acc: 0.9724 - val_loss: 0.0888 - val_acc: 0.9713\n"
     ]
    }
   ],
   "source": [
    "log = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0480141518>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log.history['loss'], label='train_set')\n",
    "plt.plot(log.history['val_loss'], label='test_set')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08641130243142446, 0.9719166666666667]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08261376172304154, 0.9730000007629395]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
